{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-ShQlRP_Hhc9"
      },
      "source": [
        "Happy Transformer: https://github.com/EricFillion/happy-transformer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "msj6TwR03MNf"
      },
      "source": [
        "pip install happytransformer"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gv_TCehj48X3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a0d36c22-f33a-4629-87fc-098a69c24025"
      },
      "source": [
        "from google.colab import drive\n",
        "from happytransformer import HappyTextClassification\n",
        "import pandas as pd\n",
        "import gzip\n",
        "import json\n",
        "\n",
        "def parse(path):\n",
        "  g = gzip.open(path, 'rb')\n",
        "  for l in g:\n",
        "    # print(l)\n",
        "    yield json.loads(l)\n",
        "\n",
        "def getDF(path, product_asin):\n",
        "  i = 0\n",
        "  df = {}\n",
        "  for d in parse(path):\n",
        "    if d.get('asin') == product_asin:\n",
        "      df[i] = d\n",
        "      i += 1\n",
        "  return pd.DataFrame.from_dict(df, orient='index')\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "json_data_path = 'drive/MyDrive/Electronics.json.gz'\n",
        "product_id = 'B003L1ZYYW'\n",
        "df = getDF(json_data_path, product_id)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.dropna(subset=['reviewText', 'summary'])\n",
        "df['reviewText'] = df['reviewText'].astype(str)\n",
        "df['summary'] = df['summary'].astype(str)\n",
        "df = df.sort_values(by='unixReviewTime', ascending=True)"
      ],
      "metadata": {
        "id": "zAw6cldUa-H7"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vi5iTnxW5B76"
      },
      "source": [
        "happy_tc = HappyTextClassification(model_type=\"DISTILBERT\", model_name=\"distilbert-base-uncased-finetuned-sst-2-english\", num_labels=2)\n",
        "tokenizer = happy_tc.tokenizer\n",
        "# Max token length (510 to account for additional special tokens) - limited by happy transformer\n",
        "MAX_TOKENS = 510"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results = []\n",
        "count = 0\n",
        "for _, row in df.iterrows():\n",
        "    # Combining summary and reviewText with a newline character in between\n",
        "    text = row[\"summary\"] + \"\\n\" + row[\"reviewText\"]\n",
        "    # Truncate the text if it exceeds the maximum token length\n",
        "    tokens = tokenizer.tokenize(text)\n",
        "    if len(tokens) > MAX_TOKENS:\n",
        "        tokens = tokens[:MAX_TOKENS]\n",
        "        text = tokenizer.decode(tokenizer.convert_tokens_to_ids(tokens))\n",
        "    sentiment = happy_tc.classify_text(text).label\n",
        "    results.append({\n",
        "        \"unixReviewTime\": row[\"unixReviewTime\"],\n",
        "        \"sentiment_pred\": int(sentiment == \"POSITIVE\")\n",
        "    })\n",
        "\n",
        "results_df = pd.DataFrame(results)"
      ],
      "metadata": {
        "id": "wLIoQCl3Zh0L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results_df.to_csv(\"drive/MyDrive/review_sentiment_preds.csv\", index=False)"
      ],
      "metadata": {
        "id": "4dViCaNScizq"
      },
      "execution_count": 34,
      "outputs": []
    }
  ]
}